{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ae7b09",
   "metadata": {},
   "source": [
    "# Treinamento e Avalia√ß√£o de Modelos\n",
    "## Tech Challenge Fase 4 - Predi√ß√£o de N√≠veis de Obesidade\n",
    "\n",
    "> üìò **Documenta√ß√£o:** Para contexto completo da estrat√©gia de modelagem e justificativas das escolhas t√©cnicas, consulte [00_GUIA_ANALISE.ipynb](00_GUIA_ANALISE.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o de bibliotecas\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    f1_score, precision_score, recall_score\n",
    ")\n",
    "\n",
    "# Modelos\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Importar tradu√ß√µes e cores padronizadas\n",
    "from translations import (\n",
    "    VARIABLE_NAMES, OBESITY_LABELS, OBESITY_ORDER,\n",
    "    PRIMARY_COLOR, SECONDARY_COLOR, ACCENT_COLOR,\n",
    "    translate_variable, get_obesity_label, get_color_palette\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "print(\"Tradu√ß√µes e cores padronizadas carregadas ‚úì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c00588",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Prepara√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset\n",
    "df = pd.read_csv('../data/Obesity.csv')\n",
    "\n",
    "# Calcular BMI\n",
    "df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n",
    "\n",
    "print(f\"üìä Dataset: {df.shape[0]} linhas, {df.shape[1]} colunas\")\n",
    "print(f\"\\nüéØ Vari√°vel Alvo: Obesity\")\n",
    "print(f\"\\nClasses: {df['Obesity'].unique()}\")\n",
    "print(f\"N√∫mero de classes: {df['Obesity'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9533e23",
   "metadata": {},
   "source": [
    "## 2. Pr√©-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features e target\n",
    "X = df.drop('Obesity', axis=1)\n",
    "y = df['Obesity']\n",
    "\n",
    "print(\"üìã Features:\")\n",
    "print(X.columns.tolist())\n",
    "print(f\"\\nTotal de features: {len(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef6eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar vari√°veis categ√≥ricas e num√©ricas\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"üìä Vari√°veis Categ√≥ricas ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"üìä Vari√°veis Num√©ricas ({len(numerical_cols)}): {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb9ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar vari√°veis categ√≥ricas\n",
    "label_encoders = {}\n",
    "X_encoded = X.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Codificar target\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "\n",
    "print(\"‚úÖ Vari√°veis categ√≥ricas codificadas!\")\n",
    "print(f\"\\nüìå Mapeamento das classes:\")\n",
    "for idx, class_name in enumerate(le_target.classes_):\n",
    "    print(f\"{idx}: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5011f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar features num√©ricas\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X_encoded.copy()\n",
    "X_scaled[numerical_cols] = scaler.fit_transform(X_encoded[numerical_cols])\n",
    "\n",
    "print(\"‚úÖ Features num√©ricas normalizadas!\")\n",
    "print(f\"\\nüìä Shape final: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02299dcd",
   "metadata": {},
   "source": [
    "## 3. Divis√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0be5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir em treino e teste (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"üìä Conjunto de Treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"üìä Conjunto de Teste: {X_test.shape[0]} amostras\")\n",
    "print(f\"\\n‚úÖ Propor√ß√£o: {X_train.shape[0]/len(X_scaled)*100:.1f}% treino / {X_test.shape[0]/len(X_scaled)*100:.1f}% teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03dfb9",
   "metadata": {},
   "source": [
    "## 4. Treinamento de Modelos Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio de modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "print(\"ü§ñ Modelos a serem treinados:\")\n",
    "for name in models.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533207b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar e avaliar modelos\n",
    "results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ TREINAMENTO DOS MODELOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ Treinando {name}...\")\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Fazer predi√ß√µes\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úÖ Acur√°cia: {accuracy*100:.2f}%\")\n",
    "    print(f\"  üìä CV Score: {cv_scores.mean()*100:.2f}% (+/- {cv_scores.std()*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ TREINAMENTO CONCLU√çDO!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320954b",
   "metadata": {},
   "source": [
    "## 5. Compara√ß√£o de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7781ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame com resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'Modelo': list(results.keys()),\n",
    "    'Acur√°cia (%)': [results[m]['accuracy']*100 for m in results.keys()],\n",
    "    'Precis√£o (%)': [results[m]['precision']*100 for m in results.keys()],\n",
    "    'Recall (%)': [results[m]['recall']*100 for m in results.keys()],\n",
    "    'F1-Score (%)': [results[m]['f1_score']*100 for m in results.keys()],\n",
    "    'CV Score (%)': [results[m]['cv_mean']*100 for m in results.keys()]\n",
    "})\n",
    "\n",
    "results_df = results_df.sort_values('Acur√°cia (%)', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nüìä COMPARA√á√ÉO DE MODELOS:\")\n",
    "print(\"=\"*100)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Identificar melhor modelo\n",
    "best_model_name = results_df.iloc[0]['Modelo']\n",
    "best_accuracy = results_df.iloc[0]['Acur√°cia (%)']\n",
    "\n",
    "print(f\"\\nüèÜ MELHOR MODELO: {best_model_name}\")\n",
    "print(f\"üéØ Acur√°cia: {best_accuracy:.2f}%\")\n",
    "\n",
    "if best_accuracy >= 75:\n",
    "    print(\"\\n‚úÖ META ATINGIDA! Acur√°cia > 75%\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Meta n√£o atingida. Necess√°rio otimizar modelos (atual: {best_accuracy:.2f}%, meta: 75%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar compara√ß√£o de modelos com cores padronizadas\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Gr√°fico de barras - Acur√°cia\n",
    "colors_bars = [SECONDARY_COLOR if acc >= 75 else ACCENT_COLOR for acc in results_df['Acur√°cia (%)']]\n",
    "axes[0].barh(results_df['Modelo'], results_df['Acur√°cia (%)'], \n",
    "            color=colors_bars, edgecolor='black', alpha=0.85, linewidth=1.2)\n",
    "axes[0].axvline(x=75, color=ACCENT_COLOR, linestyle='--', linewidth=2, label='Meta (75%)')\n",
    "axes[0].set_xlabel('Acur√°cia (%)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Compara√ß√£o de Acur√°cia dos Modelos', fontsize=14, fontweight='bold', pad=15)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for idx, val in enumerate(results_df['Acur√°cia (%)']):\n",
    "    axes[0].text(val + 0.5, idx, f'{val:.2f}%', va='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Gr√°fico de barras agrupadas - Todas as m√©tricas com cores padronizadas\n",
    "metrics_df = results_df.set_index('Modelo')[['Acur√°cia (%)', 'Precis√£o (%)', 'Recall (%)', 'F1-Score (%)']]\n",
    "\n",
    "# Criar gradiente de azul para as m√©tricas\n",
    "metric_colors = get_color_palette(4)\n",
    "metrics_df.plot(kind='bar', ax=axes[1], color=metric_colors, \n",
    "               edgecolor='black', width=0.8, alpha=0.85, linewidth=1.2)\n",
    "\n",
    "axes[1].set_title('Compara√ß√£o de M√©tricas por Modelo', fontsize=14, fontweight='bold', pad=15)\n",
    "axes[1].set_ylabel('Percentual (%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Modelo', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(title='M√©tricas', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23ae73",
   "metadata": {},
   "source": [
    "## 6. An√°lise Detalhada do Melhor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter melhor modelo\n",
    "best_model = results[best_model_name]['model']\n",
    "y_pred_best = results[best_model_name]['predictions']\n",
    "\n",
    "# Traduzir nomes das classes para portugu√™s\n",
    "class_names_pt = [get_obesity_label(cls) for cls in le_target.classes_]\n",
    "\n",
    "# Relat√≥rio de classifica√ß√£o\n",
    "print(\"\\nüìã RELAT√ìRIO DE CLASSIFICA√á√ÉO - \" + best_model_name.upper())\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred_best, \n",
    "                          target_names=class_names_pt,\n",
    "                          digits=4))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ef4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confus√£o com cores padronizadas e labels em portugu√™s\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "# Traduzir nomes das classes\n",
    "class_names_pt = [get_obesity_label(cls) for cls in le_target.classes_]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names_pt,\n",
    "            yticklabels=class_names_pt,\n",
    "            square=True, linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.8},\n",
    "            annot_kws={\"fontsize\": 10})\n",
    "plt.title(f'Matriz de Confus√£o - {best_model_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.ylabel('Classe Real', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Classe Prevista', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=9)\n",
    "plt.yticks(rotation=0, fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcular acur√°cia por classe\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "print(\"\\nüìä Acur√°cia por Classe:\")\n",
    "print(\"=\"*70)\n",
    "for idx, acc in enumerate(class_accuracy):\n",
    "    print(f\"  {class_names_pt[idx]:25s}: {acc*100:6.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b766536",
   "metadata": {},
   "source": [
    "## 7. Feature Importance (se aplic√°vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se o modelo tem feature_importances_\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Obter import√¢ncia das features\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X_scaled.columns,\n",
    "        'Feature_PT': [translate_variable(col) for col in X_scaled.columns],\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä IMPORT√ÇNCIA DAS FEATURES:\")\n",
    "    print(\"=\"*80)\n",
    "    print(feature_importance[['Feature_PT', 'Importance']].to_string(index=False))\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Visualizar top 15 features com cores padronizadas\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(15)\n",
    "    \n",
    "    bars = plt.barh(top_features['Feature_PT'], top_features['Importance'], \n",
    "                   color=SECONDARY_COLOR, edgecolor='black', alpha=0.85, linewidth=1.2)\n",
    "    plt.xlabel('Import√¢ncia', fontsize=12, fontweight='bold')\n",
    "    plt.title(f'Top 15 Features Mais Importantes - {best_model_name}', \n",
    "              fontsize=14, fontweight='bold', pad=15)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Insights sobre as features mais importantes\n",
    "    print(\"\\nüí° INSIGHTS:\")\n",
    "    print(\"=\"*80)\n",
    "    top_3 = feature_importance.head(3)\n",
    "    for idx, row in top_3.iterrows():\n",
    "        print(f\"  {idx+1}. {row['Feature_PT']}: {row['Importance']*100:.2f}% de import√¢ncia\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è {best_model_name} n√£o possui atributo feature_importances_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47929d",
   "metadata": {},
   "source": [
    "## 8. Otimiza√ß√£o do Melhor Modelo (GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ced0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir grids de hiperpar√¢metros\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Otimizar apenas se o melhor modelo estiver no dicion√°rio\n",
    "if best_model_name in param_grids:\n",
    "    print(f\"\\nüîß OTIMIZANDO {best_model_name.upper()}...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        best_model,\n",
    "        param_grids[best_model_name],\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\n‚úÖ Otimiza√ß√£o conclu√≠da!\")\n",
    "    print(f\"\\nüìä Melhores Par√¢metros:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    # Avaliar modelo otimizado\n",
    "    optimized_model = grid_search.best_estimator_\n",
    "    y_pred_optimized = optimized_model.predict(X_test)\n",
    "    optimized_accuracy = accuracy_score(y_test, y_pred_optimized)\n",
    "    \n",
    "    print(f\"\\nüìà COMPARA√á√ÉO:\")\n",
    "    print(f\"  Modelo Original: {best_accuracy:.2f}%\")\n",
    "    print(f\"  Modelo Otimizado: {optimized_accuracy*100:.2f}%\")\n",
    "    print(f\"  Melhoria: {(optimized_accuracy*100 - best_accuracy):.2f}%\")\n",
    "    \n",
    "    # Usar modelo otimizado se for melhor\n",
    "    if optimized_accuracy > results[best_model_name]['accuracy']:\n",
    "        best_model = optimized_model\n",
    "        print(\"\\n‚úÖ Modelo otimizado ser√° usado!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Modelo original teve melhor desempenho.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Grid Search n√£o configurado para {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e525be8",
   "metadata": {},
   "source": [
    "## 9. Salvar Modelo e Artefatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e9ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar modelo treinado\n",
    "model_path = '../models/best_model.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"‚úÖ Modelo salvo em: {model_path}\")\n",
    "\n",
    "# Salvar encoders\n",
    "encoders_path = '../models/label_encoders.pkl'\n",
    "joblib.dump(label_encoders, encoders_path)\n",
    "print(f\"‚úÖ Label Encoders salvos em: {encoders_path}\")\n",
    "\n",
    "# Salvar target encoder\n",
    "target_encoder_path = '../models/target_encoder.pkl'\n",
    "joblib.dump(le_target, target_encoder_path)\n",
    "print(f\"‚úÖ Target Encoder salvo em: {target_encoder_path}\")\n",
    "\n",
    "# Salvar scaler\n",
    "scaler_path = '../models/scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"‚úÖ Scaler salvo em: {scaler_path}\")\n",
    "\n",
    "# Salvar lista de features\n",
    "features_path = '../models/feature_names.pkl'\n",
    "joblib.dump(X_scaled.columns.tolist(), features_path)\n",
    "print(f\"‚úÖ Feature names salvos em: {features_path}\")\n",
    "\n",
    "# Salvar m√©tricas do modelo\n",
    "metrics_path = '../models/model_metrics.pkl'\n",
    "model_metrics = {\n",
    "    'model_name': best_model_name,\n",
    "    'accuracy': optimized_accuracy if 'optimized_accuracy' in locals() else best_accuracy/100,\n",
    "    'results_df': results_df\n",
    "}\n",
    "joblib.dump(model_metrics, metrics_path)\n",
    "print(f\"‚úÖ M√©tricas salvas em: {metrics_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ TODOS OS ARTEFATOS SALVOS COM SUCESSO!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b671d7",
   "metadata": {},
   "source": [
    "## 10. Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb93cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä RESUMO DO PROJETO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüéØ Objetivo: Acur√°cia > 75%\")\n",
    "print(f\"\\nüèÜ Melhor Modelo: {best_model_name}\")\n",
    "final_accuracy = optimized_accuracy*100 if 'optimized_accuracy' in locals() else best_accuracy\n",
    "print(f\"üìà Acur√°cia Alcan√ßada: {final_accuracy:.2f}%\")\n",
    "print(f\"\\nüì¶ Artefatos Salvos:\")\n",
    "print(f\"  - Modelo: {model_path}\")\n",
    "print(f\"  - Encoders: {encoders_path}\")\n",
    "print(f\"  - Target Encoder: {target_encoder_path}\")\n",
    "print(f\"  - Scaler: {scaler_path}\")\n",
    "print(f\"  - Features: {features_path}\")\n",
    "print(f\"  - M√©tricas: {metrics_path}\")\n",
    "print(f\"\\n‚úÖ Pr√≥ximos Passos:\")\n",
    "print(f\"  1. Desenvolver aplica√ß√£o Streamlit para predi√ß√£o\")\n",
    "print(f\"  2. Criar dashboard anal√≠tico para equipe m√©dica\")\n",
    "print(f\"  3. Documentar e testar aplica√ß√£o\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
