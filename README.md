# Tech Challenge Fase 4: PrediÃ§Ã£o de NÃ­veis de Obesidade

## ğŸ› ï¸ STATUS DO PROJETO
**âœ… PROJETO COMPLETO - Pronto para uso e avaliaÃ§Ã£o**

> ğŸ“– **Para continuar em nova sessÃ£o**: Leia [CONTEXTO_PROJETO.md](CONTEXTO_PROJETO.md) - contÃ©m o estado completo do projeto e prompt para nova sessÃ£o do Copilot.

## ğŸ¯ Objetivo Principal
Desenvolver um modelo de Machine Learning (ClassificaÃ§Ã£o Multiclasse) para prever os nÃ­veis de obesidade de pacientes. A soluÃ§Ã£o deve atingir mais de **75% de acurÃ¡cia** e ser entregue com uma aplicaÃ§Ã£o preditiva em **Streamlit** e um **Dashboard AnalÃ­tico** para a equipe mÃ©dica.

## ğŸ“Š Dataset Utilizado
O projeto utiliza o dataset `Obesity.csv` (2111 registros), focado em dados de hÃ¡bitos alimentares e histÃ³rico de saÃºde.

### VariÃ¡veis do Dataset:
- **DemogrÃ¡ficas**: Gender, Age, Height, Weight
- **HistÃ³rico**: family_history (histÃ³rico familiar de obesidade)
- **HÃ¡bitos Alimentares**: FAVC, FCVC, NCP, CAEC
- **Estilo de Vida**: SMOKE, CH2O, SCC, FAF, TUE, CALC, MTRANS
- **Alvo**: Obesity (7 classes)

### Classes de Obesidade:
1. Insufficient_Weight (Peso Insuficiente)
2. Normal_Weight (Peso Normal)
3. Overweight_Level_I (Sobrepeso NÃ­vel I)
4. Overweight_Level_II (Sobrepeso NÃ­vel II)
5. Obesity_Type_I (Obesidade Tipo I)
6. Obesity_Type_II (Obesidade Tipo II)
7. Obesity_Type_III (Obesidade Tipo III - MÃ³rbida)

## ğŸ—‚ Estrutura do RepositÃ³rio

```
fiap-tech-challenge-fase4/
â”œâ”€â”€ data/                          # Dados do projeto
â”‚   â”œâ”€â”€ Obesity.csv               # Dataset original
â”‚   â””â”€â”€ Obesity_with_BMI.csv      # Dataset com IMC calculado (gerado)
â”‚
â”œâ”€â”€ notebooks/                     # Notebooks Jupyter
â”‚   â”œâ”€â”€ 01_exploratory_data_analysis.ipynb    # AnÃ¡lise exploratÃ³ria completa
â”‚   â””â”€â”€ 02_model_training.ipynb              # Treinamento e avaliaÃ§Ã£o de modelos
â”‚
â”œâ”€â”€ src/                          # CÃ³digo fonte reutilizÃ¡vel
â”‚   â”œâ”€â”€ preprocessing.py          # FunÃ§Ãµes de preprocessamento
â”‚   â””â”€â”€ model_utils.py           # FunÃ§Ãµes de avaliaÃ§Ã£o de modelos
â”‚
â”œâ”€â”€ models/                       # Modelos treinados e artefatos
â”‚   â”œâ”€â”€ best_model.pkl           # Melhor modelo treinado
â”‚   â”œâ”€â”€ label_encoders.pkl       # Encoders para variÃ¡veis categÃ³ricas
â”‚   â”œâ”€â”€ target_encoder.pkl       # Encoder para variÃ¡vel alvo
â”‚   â”œâ”€â”€ scaler.pkl              # Scaler para normalizaÃ§Ã£o
â”‚   â”œâ”€â”€ feature_names.pkl       # Nomes das features
â”‚   â””â”€â”€ model_metrics.pkl       # MÃ©tricas do modelo
â”‚
â”œâ”€â”€ app/                         # AplicaÃ§Ãµes Streamlit
â”‚   â”œâ”€â”€ app_prediction.py       # App de prediÃ§Ã£o individual
â”‚   â””â”€â”€ app_dashboard.py        # Dashboard analÃ­tico
â”‚
â”œâ”€â”€ requirements.txt             # DependÃªncias do projeto
â”œâ”€â”€ .gitignore                  # Arquivos ignorados pelo Git
â””â”€â”€ README.md                   # Este arquivo
```

## ğŸš€ Como Executar o Projeto

### 1ï¸âƒ£ PrÃ©-requisitos
- Python 3.9+
- pip (gerenciador de pacotes Python)

### 2ï¸âƒ£ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <url-do-repositorio>
cd fiap-tech-challenge-fase4

# Crie um ambiente virtual (recomendado)
python -m venv venv

# Ative o ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Instale as dependÃªncias
pip install -r requirements.txt
```

### 3ï¸âƒ£ Executar AnÃ¡lise ExploratÃ³ria

```bash
# Abra o Jupyter Notebook
jupyter notebook

# Navegue atÃ© notebooks/01_exploratory_data_analysis.ipynb
# Execute todas as cÃ©lulas
```

**O que vocÃª verÃ¡:**
- âœ… AnÃ¡lise detalhada do dataset
- âœ… VisualizaÃ§Ãµes de distribuiÃ§Ãµes
- âœ… CorrelaÃ§Ãµes entre variÃ¡veis
- âœ… Insights sobre padrÃµes de obesidade
- âœ… CÃ¡lculo de IMC para todos os registros

### 4ï¸âƒ£ Treinar Modelos

```bash
# No Jupyter Notebook, abra:
# notebooks/02_model_training.ipynb
# Execute todas as cÃ©lulas
```

**O que acontece:**
- âœ… Preprocessamento automÃ¡tico dos dados
- âœ… Treinamento de 5 modelos diferentes:
  - Logistic Regression
  - Decision Tree
  - Random Forest
  - Gradient Boosting
  - XGBoost
- âœ… ComparaÃ§Ã£o de modelos com mÃºltiplas mÃ©tricas
- âœ… **AnÃ¡lise de Feature Importance** (identifica variÃ¡veis mais impactantes)
- âœ… OtimizaÃ§Ã£o do melhor modelo (GridSearch)
- âœ… **Feature Importance do Modelo Otimizado** (anÃ¡lise crÃ­tica)
- âœ… **Teste Experimental: Modelo Comportamental** (sem Height/Weight/BMI)
- âœ… ComparaÃ§Ã£o: Modelo Completo vs Comportamental
- âœ… Salvamento de artefatos em `models/`

**Meta:** AcurÃ¡cia > 75%

**Insights Importantes:**
- ğŸ”¬ Feature Importance revela quais variÃ¡veis sÃ£o mais importantes
- ğŸ“Š Modelo comportamental testa prediÃ§Ã£o sem mediÃ§Ãµes fÃ­sicas
- ğŸ’¡ AnÃ¡lise crÃ­tica sobre redundÃ¢ncia matemÃ¡tica de BMI

### 5ï¸âƒ£ Executar AplicaÃ§Ã£o de PrediÃ§Ã£o

```bash
# Execute a aplicaÃ§Ã£o Streamlit
streamlit run app/app_prediction.py
```

**Funcionalidades:**
- ğŸ¥ FormulÃ¡rio interativo para entrada de dados do paciente
- ğŸ¯ PrediÃ§Ã£o do nÃ­vel de obesidade
- ğŸ“Š Probabilidades para cada classe
- ğŸ’¡ RecomendaÃ§Ãµes personalizadas
- ğŸ“ˆ CÃ¡lculo automÃ¡tico de IMC

### 6ï¸âƒ£ Executar Dashboard AnalÃ­tico

```bash
# Execute o dashboard
streamlit run app/app_dashboard.py
```

**Funcionalidades:**
- ğŸ“Š KPIs principais do dataset
- ğŸ¤– MÃ©tricas de performance do modelo
- ğŸ“ˆ VisualizaÃ§Ãµes interativas:
  - DistribuiÃ§Ãµes de variÃ¡veis
  - Matriz de correlaÃ§Ã£o
  - AnÃ¡lise demogrÃ¡fica
  - HÃ¡bitos de vida
- ğŸ” Filtros dinÃ¢micos
- ğŸ’¡ Insights e recomendaÃ§Ãµes para equipe mÃ©dica

## ğŸ’» Tecnologias Utilizadas

### Core
- **Python 3.9+**: Linguagem principal
- **Pandas**: ManipulaÃ§Ã£o de dados
- **NumPy**: ComputaÃ§Ã£o numÃ©rica
- **Scikit-learn**: Machine Learning

### Machine Learning
- **RandomForestClassifier**: Modelo ensemble
- **XGBoost**: Gradient boosting otimizado
- **GradientBoostingClassifier**: Boosting tradicional
- **LabelEncoder**: CodificaÃ§Ã£o de variÃ¡veis categÃ³ricas
- **StandardScaler**: NormalizaÃ§Ã£o de features

### VisualizaÃ§Ã£o
- **Matplotlib**: GrÃ¡ficos estÃ¡ticos
- **Seaborn**: VisualizaÃ§Ãµes estatÃ­sticas
- **Plotly**: GrÃ¡ficos interativos

### AplicaÃ§Ã£o Web
- **Streamlit**: Framework para apps de ML
- **Joblib**: SerializaÃ§Ã£o de modelos

## ğŸ“ˆ Resultados Esperados

### MÃ©tricas do Modelo
- ğŸ¯ **AcurÃ¡cia**: > 75% (meta do projeto)
- ğŸ“Š **PrecisÃ£o**: Alta para todas as classes
- ğŸ”„ **Recall**: Balanceado entre classes
- ğŸ“‰ **F1-Score**: MÃ©trica harmÃ´nica otimizada

### EntregÃ¡veis
1. âœ… Notebook de EDA completo com insights
2. âœ… Notebook de treinamento com mÃºltiplos modelos
3. âœ… Modelo otimizado salvo e pronto para produÃ§Ã£o
4. âœ… AplicaÃ§Ã£o web de prediÃ§Ã£o funcional
5. âœ… Dashboard analÃ­tico interativo
6. âœ… DocumentaÃ§Ã£o completa

## ğŸ”„ Workflow do Projeto

```
1. Carregar Dados (data/Obesity.csv)
   â†“
2. AnÃ¡lise ExploratÃ³ria (EDA)
   - EstatÃ­sticas descritivas
   - VisualizaÃ§Ãµes
   - DetecÃ§Ã£o de padrÃµes
   â†“
3. Preprocessamento
   - CodificaÃ§Ã£o de categÃ³ricas
   - NormalizaÃ§Ã£o de numÃ©ricas
   - CÃ¡lculo de IMC
   â†“
4. Treinamento de Modelos
   - 5 algoritmos diferentes
   - Cross-validation
   - ComparaÃ§Ã£o de mÃ©tricas
   â†“
5. OtimizaÃ§Ã£o (GridSearch)
   - Busca de hiperparÃ¢metros
   - ValidaÃ§Ã£o cruzada
   â†“
6. Salvamento de Artefatos
   - Modelo treinado
   - Encoders e Scaler
   - MÃ©tricas
   â†“
7. Deploy em Streamlit
   - App de PrediÃ§Ã£o
   - Dashboard AnalÃ­tico
```

## ğŸ“ Conceitos de ML Aplicados

- **ClassificaÃ§Ã£o Multiclasse**: 7 classes de obesidade
- **Feature Engineering**: CriaÃ§Ã£o de IMC como feature derivada
- **Preprocessing**: Label Encoding + Standard Scaling
- **Ensemble Methods**: Random Forest, Gradient Boosting
- **Hyperparameter Tuning**: GridSearchCV
- **Cross-Validation**: ValidaÃ§Ã£o cruzada k-fold
- **Model Evaluation**: MÃºltiplas mÃ©tricas (accuracy, precision, recall, F1)

## ğŸ“ ObservaÃ§Ãµes Importantes

1. **Dados Balanceados**: Verificar balanceamento das classes no EDA
2. **Features Importantes**: Height, Weight, BMI sÃ£o altamente correlacionadas com obesidade
3. **HistÃ³rico Familiar**: Feature relevante para prediÃ§Ã£o
4. **HÃ¡bitos de Vida**: FAVC, FAF, MTRANS sÃ£o bons preditores
5. **IMC**: Feature derivada crucial para classificaÃ§Ã£o

## âš ï¸ LimitaÃ§Ãµes do Modelo

### LimitaÃ§Ãµes TÃ©cnicas:
1. **Multicolinearidade**: Height, Weight e BMI sÃ£o altamente correlacionados (VIF > 20), o que pode afetar a interpretabilidade dos coeficientes em modelos lineares
2. **Overfitting Potencial**: AcurÃ¡cia de 99.05% pode indicar ajuste excessivo aos dados de treinamento
3. **GeneralizaÃ§Ã£o**: Modelo treinado em dataset sintÃ©tico/acadÃªmico - performance em dados reais pode variar
4. **Dados SintÃ©ticos**: Dataset original possui padrÃµes muito regulares que podem nÃ£o refletir a complexidade do mundo real

### LimitaÃ§Ãµes PrÃ¡ticas:
1. **DependÃªncia de MediÃ§Ãµes**: Requer dados antropomÃ©tricos (altura, peso) que nem sempre estÃ£o disponÃ­veis
2. **Auto-reporte**: VariÃ¡veis comportamentais dependem de respostas honestas do paciente
3. **Contexto Cultural**: HÃ¡bitos alimentares e de transporte podem variar entre culturas/regiÃµes
4. **Temporal**: NÃ£o considera mudanÃ§as ao longo do tempo (snapshot Ãºnico)

### LimitaÃ§Ãµes de AplicaÃ§Ã£o:
1. **NÃ£o Ã© DiagnÃ³stico MÃ©dico**: Ferramenta de apoio, nÃ£o substitui avaliaÃ§Ã£o mÃ©dica profissional
2. **Faixa EtÃ¡ria**: NÃ£o validado para crianÃ§as, adolescentes ou idosos
3. **CondiÃ§Ãµes Especiais**: NÃ£o considera gestaÃ§Ã£o, condiÃ§Ãµes mÃ©dicas especiais, atletas
4. **ViÃ©s de Amostra**: Dataset pode nÃ£o representar adequadamente todas as populaÃ§Ãµes

## ğŸ› Troubleshooting

### Erro ao carregar modelo
```python
# Certifique-se de executar o notebook de treinamento primeiro
# Os modelos devem estar em models/
```

### Erro de importaÃ§Ã£o
```bash
# Reinstale as dependÃªncias
pip install -r requirements.txt --upgrade
```

### Streamlit nÃ£o abre
```bash
# Verifique se estÃ¡ na pasta correta
# Execute: streamlit run app/app_prediction.py
# Acesse: http://localhost:8501
```

## ğŸ“š PrÃ³ximos Passos (Melhorias Futuras)

### ğŸ”¬ Melhorias no Modelo:
- [ ] **ValidaÃ§Ã£o Cruzada Estratificada**: Implementar StratifiedKFold para garantir distribuiÃ§Ã£o equilibrada
- [ ] **Feature Engineering AvanÃ§ado**: Criar razÃµes e interaÃ§Ãµes entre features (ex: razÃ£o cintura-quadril)
- [ ] **Ensemble Learning**: Combinar mÃºltiplos modelos (Voting/Stacking) para melhor generalizaÃ§Ã£o
- [ ] **RegularizaÃ§Ã£o**: Adicionar L1/L2 para reduzir overfitting
- [ ] **AnÃ¡lise de ViÃ©s**: Avaliar performance por gÃªnero, idade, etnia

### ğŸ“Š Melhorias nos Dados:
- [ ] **Coleta de Dados Reais**: Validar modelo com dados clÃ­nicos reais
- [ ] **Aumento de Dataset**: Incorporar mais variÃ¡veis (glicemia, pressÃ£o arterial, colesterol)
- [ ] **Dados Temporais**: Coletar histÃ³rico longitudinal para prever progressÃ£o
- [ ] **SMOTE/ADASYN**: Balanceamento inteligente se houver desbalanceamento

### ğŸ’» Melhorias TÃ©cnicas:
- [ ] **Testes Automatizados**: Implementar pytest para validaÃ§Ã£o contÃ­nua
- [ ] **CI/CD Pipeline**: GitHub Actions para testes e deploy automÃ¡tico
- [ ] **API REST**: Criar FastAPI para integraÃ§Ã£o com sistemas externos
- [ ] **ContainerizaÃ§Ã£o**: Docker para facilitar deployment
- [ ] **Monitoramento**: MLflow para tracking de experimentos e mÃ©tricas
- [ ] **Versionamento de Dados**: DVC para gerenciar datasets e modelos

### ğŸš€ Melhorias nas AplicaÃ§Ãµes:
- [ ] **AutenticaÃ§Ã£o**: Sistema de login para controle de acesso
- [ ] **HistÃ³rico de PrediÃ§Ãµes**: Armazenar e visualizar prediÃ§Ãµes anteriores
- [ ] **ComparaÃ§Ã£o Temporal**: Acompanhar evoluÃ§Ã£o do paciente ao longo do tempo
- [ ] **Exportar RelatÃ³rios**: Gerar PDFs com resultados e recomendaÃ§Ãµes
- [ ] **Mobile App**: VersÃ£o para smartphones (React Native/Flutter)
- [ ] **Chatbot**: Interface conversacional para coleta de dados

### ğŸ§  Melhorias em Interpretabilidade:
- [ ] **SHAP Values**: Explicabilidade detalhada das prediÃ§Ãµes
- [ ] **LIME**: ExplicaÃ§Ãµes locais para casos individuais
- [ ] **Feature Importance Plots**: VisualizaÃ§Ãµes interativas
- [ ] **Counterfactual Explanations**: "O que mudaria o resultado?"

### ğŸŒ Deployment e Escalabilidade:
- [ ] **Cloud Deployment**: AWS/GCP/Azure para escalabilidade
- [ ] **Load Balancing**: Suportar mÃºltiplos usuÃ¡rios simultÃ¢neos
- [ ] **Edge Computing**: Executar modelo em dispositivos locais
- [ ] **Batch Processing**: Pipeline para processar mÃºltiplos pacientes

### ğŸ“ˆ ExtensÃµes do Projeto:
- [ ] **Modelo de SÃ©ries Temporais**: Prever evoluÃ§Ã£o futura da obesidade
- [ ] **Sistema de RecomendaÃ§Ã£o**: Planos personalizados de dieta/exercÃ­cio
- [ ] **GamificaÃ§Ã£o**: Sistema de pontos/badges para engajar usuÃ¡rios
- [ ] **IntegraÃ§Ã£o com Wearables**: Fitbit, Apple Watch, etc.

## ğŸ‘¥ Grupo

**POSTECH Data Analytics - 9DTAT**  
Tech Challenge - Fase 4

**Integrantes:**
- Thiago Cesar Silva
- Vitor da Silva Ammari
- JoÃ£o Marcos Marques Messias
- JoÃ£o Pedro de Jesus
- Nykolas Vieira Albino dos Santos

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para fins educacionais como parte do Tech Challenge da POSTECH.

---

**Desenvolvido para o Tech Challenge Fase 4 - POSTECH Data Analytics - 9DTAT**
